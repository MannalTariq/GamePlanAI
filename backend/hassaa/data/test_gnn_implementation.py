import os
import torch
import numpy as np
from torch_geometric.data import Data

# Fix imports - handle both module and direct execution
try:
    # When running as module
    from .models.gatv2_models import MultiTaskGATv2, SingleTaskGATv2Shot, SingleTaskGATv2Receiver
    from .gnn_dataset import SetPieceGraphDataset
except ImportError:
    # When running directly
    try:
        from models.gatv2_models import MultiTaskGATv2, SingleTaskGATv2Shot, SingleTaskGATv2Receiver
        from gnn_dataset import SetPieceGraphDataset
    except ImportError:
        # Last resort - add to path
        import sys
        sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
        from models.gatv2_models import MultiTaskGATv2, SingleTaskGATv2Shot, SingleTaskGATv2Receiver
        from gnn_dataset import SetPieceGraphDataset

from gnn_train import pairwise_ranking_loss, evaluate_receiver_node_ranking

def test_model_architectures():
    """Test that all model architectures can be instantiated and run forward pass"""
    print("=== TESTING MODEL ARCHITECTURES ===")
    
    # Test data
    num_nodes = 10
    num_edges = 20
    num_features = 21  # Updated to match our enhanced feature set
    num_edge_features = 4
    
    # Create sample graph data
    x = torch.randn(num_nodes, num_features)
    edge_index = torch.randint(0, num_nodes, (2, num_edges))
    edge_attr = torch.randn(num_edges, num_edge_features)
    batch = torch.zeros(num_nodes, dtype=torch.long)
    y_shot = torch.tensor([1.0])
    y_receiver = torch.zeros(num_nodes)
    y_receiver[3] = 1.0  # Make node 3 the receiver
    
    data = Data(
        x=x,
        edge_index=edge_index,
        edge_attr=edge_attr,
        y_shot=y_shot,
        y_receiver=y_receiver,
        batch=batch
    )
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    data = data.to(device)
    
    # Test MultiTaskGATv2
    print("Testing MultiTaskGATv2...")
    model = MultiTaskGATv2(in_dim=num_features, hidden=64, heads=4, dropout=0.2, edge_dim=num_edge_features)
    model = model.to(device)
    
    model.train()
    receiver_logits, shot_logits = model(data)
    
    assert receiver_logits.shape == (num_nodes, 1), f"Expected receiver_logits shape {(num_nodes, 1)}, got {receiver_logits.shape}"
    assert shot_logits.shape == (1, 1), f"Expected shot_logits shape {(1, 1)}, got {shot_logits.shape}"
    
    model.eval()
    with torch.no_grad():
        receiver_logits, shot_logits = model(data)
        assert receiver_logits.shape == (num_nodes, 1)
        assert shot_logits.shape == (1, 1)
    
    print("‚úì MultiTaskGATv2 passed")
    
    # Test SingleTaskGATv2Shot
    print("Testing SingleTaskGATv2Shot...")
    shot_model = SingleTaskGATv2Shot(in_dim=num_features, hidden=64, heads=4, dropout=0.2, edge_dim=num_edge_features)
    shot_model = shot_model.to(device)
    
    shot_model.train()
    shot_logits = shot_model(data)
    assert shot_logits.shape == (1, 1), f"Expected shot_logits shape {(1, 1)}, got {shot_logits.shape}"
    
    shot_model.eval()
    with torch.no_grad():
        shot_logits = shot_model(data)
        assert shot_logits.shape == (1, 1)
    
    print("‚úì SingleTaskGATv2Shot passed")
    
    # Test SingleTaskGATv2Receiver
    print("Testing SingleTaskGATv2Receiver...")
    receiver_model = SingleTaskGATv2Receiver(in_dim=num_features, hidden=64, heads=4, dropout=0.2, edge_dim=num_edge_features)
    receiver_model = receiver_model.to(device)
    
    receiver_model.train()
    receiver_logits = receiver_model(data)
    assert receiver_logits.shape == (num_nodes, 1), f"Expected receiver_logits shape {(num_nodes, 1)}, got {receiver_logits.shape}"
    
    receiver_model.eval()
    with torch.no_grad():
        receiver_logits = receiver_model(data)
        assert receiver_logits.shape == (num_nodes, 1)
    
    print("‚úì SingleTaskGATv2Receiver passed")
    
    print("=== ALL MODEL ARCHITECTURES PASSED ===\n")


def test_dataset_creation():
    """Test that dataset can be created and loaded"""
    print("=== TESTING DATASET CREATION ===")
    
    root = os.path.dirname(__file__)
    
    try:
        # Try to create a small dataset for testing
        ds = SetPieceGraphDataset(
            root=root, 
            is_train=True, 
            radius_m=15.0, 
            knn_k=4,
            save_sample_path=os.path.join(root, "test_sample_graph.json")
        )
        
        print(f"Dataset created with {len(ds)} graphs")
        
        if len(ds) > 0:
            # Test accessing a sample
            sample = ds[0]
            print(f"Sample graph has {sample.num_nodes} nodes and {sample.edge_index.size(1)} edges")
            print(f"Node features: {sample.x.shape}")
            print(f"Edge features: {sample.edge_attr.shape if sample.edge_attr is not None else 'None'}")
            print(f"Shot label: {sample.y_shot}")
            print(f"Receiver labels: {sample.y_receiver.sum().item()} positive")
            
            # Verify feature dimensions
            expected_node_features = 21  # Our enhanced feature set
            assert sample.x.shape[1] == expected_node_features, f"Expected {expected_node_features} node features, got {sample.x.shape[1]}"
            
            if sample.edge_attr is not None:
                expected_edge_features = 4
                assert sample.edge_attr.shape[1] == expected_edge_features, f"Expected {expected_edge_features} edge features, got {sample.edge_attr.shape[1]}"
            
            print("‚úì Dataset creation and sample access passed")
        else:
            print("‚ö† Dataset is empty - may need to run preprocessing first")
            
    except FileNotFoundError as e:
        print(f"‚ö† Dataset files not found - may need to run preprocessing first: {e}")
    except Exception as e:
        print(f"‚ö† Dataset test encountered an issue: {e}")
    
    print("=== DATASET TEST COMPLETE ===\n")


def test_loss_functions():
    """Test loss functions used in training"""
    print("=== TESTING LOSS FUNCTIONS ===")
    
    from gnn_train import pairwise_ranking_loss
    
    # Create test data
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Test pairwise ranking loss
    node_logits = torch.randn(10, 1, device=device)
    y_receiver = torch.zeros(10, device=device)
    y_receiver[2] = 1.0  # Positive example
    y_receiver[7] = 1.0  # Another positive example
    batch = torch.zeros(10, dtype=torch.long, device=device)
    
    loss = pairwise_ranking_loss(node_logits, y_receiver, batch, margin=0.5, negatives_per_pos=3)
    
    assert isinstance(loss, torch.Tensor), "Loss should be a tensor"
    assert loss.dim() == 0, "Loss should be a scalar"
    assert loss.item() >= 0, "Loss should be non-negative"
    
    print(f"Pairwise ranking loss: {loss.item():.4f}")
    print("‚úì Loss functions passed")
    
    print("=== LOSS FUNCTION TEST COMPLETE ===\n")


def test_evaluation_metrics():
    """Test evaluation metrics"""
    print("=== TESTING EVALUATION METRICS ===")
    
    from gnn_train import precision_at_k, map_at_k, ndcg_at_k, evaluate_receiver_node_ranking
    
    # Test ranking metrics
    scores = np.array([0.9, 0.3, 0.8, 0.1, 0.7])
    labels = np.array([1, 0, 1, 0, 0])
    
    # Test precision@k
    p1 = precision_at_k(scores, labels, 1)
    p3 = precision_at_k(scores, labels, 3)
    print(f"Precision@1: {p1:.3f}, Precision@3: {p3:.3f}")
    
    # Test MAP@k
    map3 = map_at_k(scores, labels, 3)
    print(f"MAP@3: {map3:.3f}")
    
    # Test NDCG@k
    ndcg3 = ndcg_at_k(scores, labels, 3)
    print(f"NDCG@3: {ndcg3:.3f}")
    
    # Test receiver evaluation function
    node_logits = torch.tensor([[0.9], [0.3], [0.8], [0.1], [0.7]])
    batch = torch.tensor([0, 0, 0, 0, 0])
    x = torch.ones(5, 21)  # 21 features
    x[:, 4] = torch.tensor([1, 1, 1, 0, 0])  # First 3 are attackers
    y_receiver = torch.tensor([1.0, 0.0, 1.0, 0.0, 0.0])
    
    metrics = evaluate_receiver_node_ranking(node_logits, batch, x, y_receiver)
    print(f"Receiver metrics: {metrics}")
    
    print("‚úì Evaluation metrics passed")
    
    print("=== EVALUATION METRICS TEST COMPLETE ===\n")


def run_all_tests():
    """Run all tests"""
    print("Starting GNN implementation tests...\n")
    
    try:
        test_model_architectures()
        test_dataset_creation()
        test_loss_functions()
        test_evaluation_metrics()
        
        print("=== ALL TESTS PASSED SUCCESSFULLY ===")
        print("\nYour GATv2 implementation is ready for training!")
        return True
        
    except Exception as e:
        print(f"‚ùå TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    torch.manual_seed(42)
    np.random.seed(42)
    success = run_all_tests()
    
    if success:
        print("\nüéâ All tests passed! Your GNN implementation is working correctly.")
    else:
        print("\n‚ùå Some tests failed. Please check the implementation.")